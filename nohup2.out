INFO:root:called-params configs/in1k_vith14_ep300_fextrc.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 16,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'image_folder': 'LifeCLEFPlant2022/',
                'num_workers': 32,
                'pin_mem': True,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/inet_feature_extraction',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.996, 1.0],
                        'epochs': 350,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'lr': 0.001,
                        'start_lr': 0.0002,
                        'warmup': 40,
                        'weight_decay': 0.04}}
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
  )
  (blocks): ModuleList(
    (0-31): 32 x Block(
      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1280, out_features=3840, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1280, out_features=1280, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=1280, out_features=5120, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
)
INFO:root:making imagenet data transforms
INFO:root:data-path /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/train/
INFO:root:Initialized PC2022
INFO:root:PlantCLEF dataset created
INFO:root:loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
INFO:root:Encountered exception when loading checkpoint 'NoneType' object has no attribute 'load_state_dict'
/home/rtcalumby/miniconda3/envs/py382/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Image(s) Shape: torch.Size([16, 3, 224, 224])
Mask Context Encoder List: [tensor([[  0,   1,   2,  ..., 190, 192, 193],
        [  0,   1,   2,  ..., 179, 180, 181],
        [  0,   1,   2,  ..., 211, 212, 213],
        ...,
        [  0,   1,   2,  ..., 224, 237, 238],
        [  0,   1,   2,  ..., 186, 187, 188],
        [  0,   1,   2,  ..., 216, 217, 218]], device='cuda:0')]
Mask Context Encoder Length 85
Mask Target Shape: [tensor([[ 21,  22,  23,  24,  25,  26,  37,  38,  39,  40,  41,  42,  53,  54,
          55,  56,  57,  58,  69,  70,  71,  72,  73,  74,  85,  86,  87,  88,
          89,  90, 101, 102, 103, 104, 105, 106, 117, 118, 119, 120, 121, 122],
        [ 69,  70,  71,  72,  73,  74,  85,  86,  87,  88,  89,  90, 101, 102,
         103, 104, 105, 106, 117, 118, 119, 120, 121, 122, 133, 134, 135, 136,
         137, 138, 149, 150, 151, 152, 153, 154, 165, 166, 167, 168, 169, 170],
        [ 57,  58,  59,  60,  61,  62,  73,  74,  75,  76,  77,  78,  89,  90,
          91,  92,  93,  94, 105, 106, 107, 108, 109, 110, 121, 122, 123, 124,
         125, 126, 137, 138, 139, 140, 141, 142, 153, 154, 155, 156, 157, 158],
        [  2,   3,   4,   5,   6,   7,  18,  19,  20,  21,  22,  23,  34,  35,
          36,  37,  38,  39,  50,  51,  52,  53,  54,  55,  66,  67,  68,  69,
          70,  71,  82,  83,  84,  85,  86,  87,  98,  99, 100, 101, 102, 103],
        [ 80,  81,  82,  83,  84,  85,  96,  97,  98,  99, 100, 101, 112, 113,
         114, 115, 116, 117, 128, 129, 130, 131, 132, 133, 144, 145, 146, 147,
         148, 149, 160, 161, 162, 163, 164, 165, 176, 177, 178, 179, 180, 181],
        [ 36,  37,  38,  39,  40,  41,  52,  53,  54,  55,  56,  57,  68,  69,
          70,  71,  72,  73,  84,  85,  86,  87,  88,  89, 100, 101, 102, 103,
         104, 105, 116, 117, 118, 119, 120, 121, 132, 133, 134, 135, 136, 137],
        [  7,   8,   9,  10,  11,  12,  23,  24,  25,  26,  27,  28,  39,  40,
          41,  42,  43,  44,  55,  56,  57,  58,  59,  60,  71,  72,  73,  74,
          75,  76,  87,  88,  89,  90,  91,  92, 103, 104, 105, 106, 107, 108],
        [101, 102, 103, 104, 105, 106, 117, 118, 119, 120, 121, 122, 133, 134,
         135, 136, 137, 138, 149, 150, 151, 152, 153, 154, 165, 166, 167, 168,
         169, 170, 181, 182, 183, 184, 185, 186, 197, 198, 199, 200, 201, 202],
        [ 56,  57,  58,  59,  60,  61,  72,  73,  74,  75,  76,  77,  88,  89,
          90,  91,  92,  93, 104, 105, 106, 107, 108, 109, 120, 121, 122, 123,
         124, 125, 136, 137, 138, 139, 140, 141, 152, 153, 154, 155, 156, 157],
        [ 57,  58,  59,  60,  61,  62,  73,  74,  75,  76,  77,  78,  89,  90,
          91,  92,  93,  94, 105, 106, 107, 108, 109, 110, 121, 122, 123, 124,
         125, 126, 137, 138, 139, 140, 141, 142, 153, 154, 155, 156, 157, 158],
        [  4,   5,   6,   7,   8,   9,  20,  21,  22,  23,  24,  25,  36,  37,
          38,  39,  40,  41,  52,  53,  54,  55,  56,  57,  68,  69,  70,  71,
          72,  73,  84,  85,  86,  87,  88,  89, 100, 101, 102, 103, 104, 105],
        [ 50,  51,  52,  53,  54,  55,  66,  67,  68,  69,  70,  71,  82,  83,
          84,  85,  86,  87,  98,  99, 100, 101, 102, 103, 114, 115, 116, 117,
         118, 119, 130, 131, 132, 133, 134, 135, 146, 147, 148, 149, 150, 151],
        [128, 129, 130, 131, 132, 133, 144, 145, 146, 147, 148, 149, 160, 161,
         162, 163, 164, 165, 176, 177, 178, 179, 180, 181, 192, 193, 194, 195,
         196, 197, 208, 209, 210, 211, 212, 213, 224, 225, 226, 227, 228, 229],
        [135, 136, 137, 138, 139, 140, 151, 152, 153, 154, 155, 156, 167, 168,
         169, 170, 171, 172, 183, 184, 185, 186, 187, 188, 199, 200, 201, 202,
         203, 204, 215, 216, 217, 218, 219, 220, 231, 232, 233, 234, 235, 236],
        [ 18,  19,  20,  21,  22,  23,  34,  35,  36,  37,  38,  39,  50,  51,
          52,  53,  54,  55,  66,  67,  68,  69,  70,  71,  82,  83,  84,  85,
          86,  87,  98,  99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119],
        [  8,   9,  10,  11,  12,  13,  24,  25,  26,  27,  28,  29,  40,  41,
          42,  43,  44,  45,  56,  57,  58,  59,  60,  61,  72,  73,  74,  75,
          76,  77,  88,  89,  90,  91,  92,  93, 104, 105, 106, 107, 108, 109]],
       device='cuda:0'), tensor([[ 80,  81,  82,  83,  84,  85,  96,  97,  98,  99, 100, 101, 112, 113,
         114, 115, 116, 117, 128, 129, 130, 131, 132, 133, 144, 145, 146, 147,
         148, 149, 160, 161, 162, 163, 164, 165, 176, 177, 178, 179, 180, 181],
        [105, 106, 107, 108, 109, 110, 121, 122, 123, 124, 125, 126, 137, 138,
         139, 140, 141, 142, 153, 154, 155, 156, 157, 158, 169, 170, 171, 172,
         173, 174, 185, 186, 187, 188, 189, 190, 201, 202, 203, 204, 205, 206],
        [ 99, 100, 101, 102, 103, 104, 115, 116, 117, 118, 119, 120, 131, 132,
         133, 134, 135, 136, 147, 148, 149, 150, 151, 152, 163, 164, 165, 166,
         167, 168, 179, 180, 181, 182, 183, 184, 195, 196, 197, 198, 199, 200],
        [ 67,  68,  69,  70,  71,  72,  83,  84,  85,  86,  87,  88,  99, 100,
         101, 102, 103, 104, 115, 116, 117, 118, 119, 120, 131, 132, 133, 134,
         135, 136, 147, 148, 149, 150, 151, 152, 163, 164, 165, 166, 167, 168],
        [ 22,  23,  24,  25,  26,  27,  38,  39,  40,  41,  42,  43,  54,  55,
          56,  57,  58,  59,  70,  71,  72,  73,  74,  75,  86,  87,  88,  89,
          90,  91, 102, 103, 104, 105, 106, 107, 118, 119, 120, 121, 122, 123],
        [104, 105, 106, 107, 108, 109, 120, 121, 122, 123, 124, 125, 136, 137,
         138, 139, 140, 141, 152, 153, 154, 155, 156, 157, 168, 169, 170, 171,
         172, 173, 184, 185, 186, 187, 188, 189, 200, 201, 202, 203, 204, 205],
        [135, 136, 137, 138, 139, 140, 151, 152, 153, 154, 155, 156, 167, 168,
         169, 170, 171, 172, 183, 184, 185, 186, 187, 188, 199, 200, 201, 202,
         203, 204, 215, 216, 217, 218, 219, 220, 231, 232, 233, 234, 235, 236],
        [ 98,  99, 100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 130, 131,
         132, 133, 134, 135, 146, 147, 148, 149, 150, 151, 162, 163, 164, 165,
         166, 167, 178, 179, 180, 181, 182, 183, 194, 195, 196, 197, 198, 199],
        [ 85,  86,  87,  88,  89,  90, 101, 102, 103, 104, 105, 106, 117, 118,
         119, 120, 121, 122, 133, 134, 135, 136, 137, 138, 149, 150, 151, 152,
         153, 154, 165, 166, 167, 168, 169, 170, 181, 182, 183, 184, 185, 186],
        [ 89,  90,  91,  92,  93,  94, 105, 106, 107, 108, 109, 110, 121, 122,
         123, 124, 125, 126, 137, 138, 139, 140, 141, 142, 153, 154, 155, 156,
         157, 158, 169, 170, 171, 172, 173, 174, 185, 186, 187, 188, 189, 190],
        [ 24,  25,  26,  27,  28,  29,  40,  41,  42,  43,  44,  45,  56,  57,
          58,  59,  60,  61,  72,  73,  74,  75,  76,  77,  88,  89,  90,  91,
          92,  93, 104, 105, 106, 107, 108, 109, 120, 121, 122, 123, 124, 125],
        [ 40,  41,  42,  43,  44,  45,  56,  57,  58,  59,  60,  61,  72,  73,
          74,  75,  76,  77,  88,  89,  90,  91,  92,  93, 104, 105, 106, 107,
         108, 109, 120, 121, 122, 123, 124, 125, 136, 137, 138, 139, 140, 141],
        [ 19,  20,  21,  22,  23,  24,  35,  36,  37,  38,  39,  40,  51,  52,
          53,  54,  55,  56,  67,  68,  69,  70,  71,  72,  83,  84,  85,  86,
          87,  88,  99, 100, 101, 102, 103, 104, 115, 116, 117, 118, 119, 120],
        [  6,   7,   8,   9,  10,  11,  22,  23,  24,  25,  26,  27,  38,  39,
          40,  41,  42,  43,  54,  55,  56,  57,  58,  59,  70,  71,  72,  73,
          74,  75,  86,  87,  88,  89,  90,  91, 102, 103, 104, 105, 106, 107],
        [ 53,  54,  55,  56,  57,  58,  69,  70,  71,  72,  73,  74,  85,  86,
          87,  88,  89,  90, 101, 102, 103, 104, 105, 106, 117, 118, 119, 120,
         121, 122, 133, 134, 135, 136, 137, 138, 149, 150, 151, 152, 153, 154],
        [ 80,  81,  82,  83,  84,  85,  96,  97,  98,  99, 100, 101, 112, 113,
         114, 115, 116, 117, 128, 129, 130, 131, 132, 133, 144, 145, 146, 147,
         148, 149, 160, 161, 162, 163, 164, 165, 176, 177, 178, 179, 180, 181]],
       device='cuda:0'), tensor([[ 82,  83,  84,  85,  86,  87,  98,  99, 100, 101, 102, 103, 114, 115,
         116, 117, 118, 119, 130, 131, 132, 133, 134, 135, 146, 147, 148, 149,
         150, 151, 162, 163, 164, 165, 166, 167, 178, 179, 180, 181, 182, 183],
        [ 52,  53,  54,  55,  56,  57,  68,  69,  70,  71,  72,  73,  84,  85,
          86,  87,  88,  89, 100, 101, 102, 103, 104, 105, 116, 117, 118, 119,
         120, 121, 132, 133, 134, 135, 136, 137, 148, 149, 150, 151, 152, 153],
        [ 23,  24,  25,  26,  27,  28,  39,  40,  41,  42,  43,  44,  55,  56,
          57,  58,  59,  60,  71,  72,  73,  74,  75,  76,  87,  88,  89,  90,
          91,  92, 103, 104, 105, 106, 107, 108, 119, 120, 121, 122, 123, 124],
        [ 80,  81,  82,  83,  84,  85,  96,  97,  98,  99, 100, 101, 112, 113,
         114, 115, 116, 117, 128, 129, 130, 131, 132, 133, 144, 145, 146, 147,
         148, 149, 160, 161, 162, 163, 164, 165, 176, 177, 178, 179, 180, 181],
        [ 82,  83,  84,  85,  86,  87,  98,  99, 100, 101, 102, 103, 114, 115,
         116, 117, 118, 119, 130, 131, 132, 133, 134, 135, 146, 147, 148, 149,
         150, 151, 162, 163, 164, 165, 166, 167, 178, 179, 180, 181, 182, 183],
        [ 23,  24,  25,  26,  27,  28,  39,  40,  41,  42,  43,  44,  55,  56,
          57,  58,  59,  60,  71,  72,  73,  74,  75,  76,  87,  88,  89,  90,
          91,  92, 103, 104, 105, 106, 107, 108, 119, 120, 121, 122, 123, 124],
        [ 65,  66,  67,  68,  69,  70,  81,  82,  83,  84,  85,  86,  97,  98,
          99, 100, 101, 102, 113, 114, 115, 116, 117, 118, 129, 130, 131, 132,
         133, 134, 145, 146, 147, 148, 149, 150, 161, 162, 163, 164, 165, 166],
        [ 34,  35,  36,  37,  38,  39,  50,  51,  52,  53,  54,  55,  66,  67,
          68,  69,  70,  71,  82,  83,  84,  85,  86,  87,  98,  99, 100, 101,
         102, 103, 114, 115, 116, 117, 118, 119, 130, 131, 132, 133, 134, 135],
        [ 70,  71,  72,  73,  74,  75,  86,  87,  88,  89,  90,  91, 102, 103,
         104, 105, 106, 107, 118, 119, 120, 121, 122, 123, 134, 135, 136, 137,
         138, 139, 150, 151, 152, 153, 154, 155, 166, 167, 168, 169, 170, 171],
        [  4,   5,   6,   7,   8,   9,  20,  21,  22,  23,  24,  25,  36,  37,
          38,  39,  40,  41,  52,  53,  54,  55,  56,  57,  68,  69,  70,  71,
          72,  73,  84,  85,  86,  87,  88,  89, 100, 101, 102, 103, 104, 105],
        [ 24,  25,  26,  27,  28,  29,  40,  41,  42,  43,  44,  45,  56,  57,
          58,  59,  60,  61,  72,  73,  74,  75,  76,  77,  88,  89,  90,  91,
          92,  93, 104, 105, 106, 107, 108, 109, 120, 121, 122, 123, 124, 125],
        [  5,   6,   7,   8,   9,  10,  21,  22,  23,  24,  25,  26,  37,  38,
          39,  40,  41,  42,  53,  54,  55,  56,  57,  58,  69,  70,  71,  72,
          73,  74,  85,  86,  87,  88,  89,  90, 101, 102, 103, 104, 105, 106],
        [ 85,  86,  87,  88,  89,  90, 101, 102, 103, 104, 105, 106, 117, 118,
         119, 120, 121, 122, 133, 134, 135, 136, 137, 138, 149, 150, 151, 152,
         153, 154, 165, 166, 167, 168, 169, 170, 181, 182, 183, 184, 185, 186],
        [ 88,  89,  90,  91,  92,  93, 104, 105, 106, 107, 108, 109, 120, 121,
         122, 123, 124, 125, 136, 137, 138, 139, 140, 141, 152, 153, 154, 155,
         156, 157, 168, 169, 170, 171, 172, 173, 184, 185, 186, 187, 188, 189],
        [ 53,  54,  55,  56,  57,  58,  69,  70,  71,  72,  73,  74,  85,  86,
          87,  88,  89,  90, 101, 102, 103, 104, 105, 106, 117, 118, 119, 120,
         121, 122, 133, 134, 135, 136, 137, 138, 149, 150, 151, 152, 153, 154],
        [ 97,  98,  99, 100, 101, 102, 113, 114, 115, 116, 117, 118, 129, 130,
         131, 132, 133, 134, 145, 146, 147, 148, 149, 150, 161, 162, 163, 164,
         165, 166, 177, 178, 179, 180, 181, 182, 193, 194, 195, 196, 197, 198]],
       device='cuda:0'), tensor([[132, 133, 134, 135, 136, 137, 148, 149, 150, 151, 152, 153, 164, 165,
         166, 167, 168, 169, 180, 181, 182, 183, 184, 185, 196, 197, 198, 199,
         200, 201, 212, 213, 214, 215, 216, 217, 228, 229, 230, 231, 232, 233],
        [ 35,  36,  37,  38,  39,  40,  51,  52,  53,  54,  55,  56,  67,  68,
          69,  70,  71,  72,  83,  84,  85,  86,  87,  88,  99, 100, 101, 102,
         103, 104, 115, 116, 117, 118, 119, 120, 131, 132, 133, 134, 135, 136],
        [ 97,  98,  99, 100, 101, 102, 113, 114, 115, 116, 117, 118, 129, 130,
         131, 132, 133, 134, 145, 146, 147, 148, 149, 150, 161, 162, 163, 164,
         165, 166, 177, 178, 179, 180, 181, 182, 193, 194, 195, 196, 197, 198],
        [ 54,  55,  56,  57,  58,  59,  70,  71,  72,  73,  74,  75,  86,  87,
          88,  89,  90,  91, 102, 103, 104, 105, 106, 107, 118, 119, 120, 121,
         122, 123, 134, 135, 136, 137, 138, 139, 150, 151, 152, 153, 154, 155],
        [118, 119, 120, 121, 122, 123, 134, 135, 136, 137, 138, 139, 150, 151,
         152, 153, 154, 155, 166, 167, 168, 169, 170, 171, 182, 183, 184, 185,
         186, 187, 198, 199, 200, 201, 202, 203, 214, 215, 216, 217, 218, 219],
        [ 67,  68,  69,  70,  71,  72,  83,  84,  85,  86,  87,  88,  99, 100,
         101, 102, 103, 104, 115, 116, 117, 118, 119, 120, 131, 132, 133, 134,
         135, 136, 147, 148, 149, 150, 151, 152, 163, 164, 165, 166, 167, 168],
        [ 56,  57,  58,  59,  60,  61,  72,  73,  74,  75,  76,  77,  88,  89,
          90,  91,  92,  93, 104, 105, 106, 107, 108, 109, 120, 121, 122, 123,
         124, 125, 136, 137, 138, 139, 140, 141, 152, 153, 154, 155, 156, 157],
        [119, 120, 121, 122, 123, 124, 135, 136, 137, 138, 139, 140, 151, 152,
         153, 154, 155, 156, 167, 168, 169, 170, 171, 172, 183, 184, 185, 186,
         187, 188, 199, 200, 201, 202, 203, 204, 215, 216, 217, 218, 219, 220],
        [ 80,  81,  82,  83,  84,  85,  96,  97,  98,  99, 100, 101, 112, 113,
         114, 115, 116, 117, 128, 129, 130, 131, 132, 133, 144, 145, 146, 147,
         148, 149, 160, 161, 162, 163, 164, 165, 176, 177, 178, 179, 180, 181],
        [ 16,  17,  18,  19,  20,  21,  32,  33,  34,  35,  36,  37,  48,  49,
          50,  51,  52,  53,  64,  65,  66,  67,  68,  69,  80,  81,  82,  83,
          84,  85,  96,  97,  98,  99, 100, 101, 112, 113, 114, 115, 116, 117],
        [ 39,  40,  41,  42,  43,  44,  55,  56,  57,  58,  59,  60,  71,  72,
          73,  74,  75,  76,  87,  88,  89,  90,  91,  92, 103, 104, 105, 106,
         107, 108, 119, 120, 121, 122, 123, 124, 135, 136, 137, 138, 139, 140],
        [ 89,  90,  91,  92,  93,  94, 105, 106, 107, 108, 109, 110, 121, 122,
         123, 124, 125, 126, 137, 138, 139, 140, 141, 142, 153, 154, 155, 156,
         157, 158, 169, 170, 171, 172, 173, 174, 185, 186, 187, 188, 189, 190],
        [ 66,  67,  68,  69,  70,  71,  82,  83,  84,  85,  86,  87,  98,  99,
         100, 101, 102, 103, 114, 115, 116, 117, 118, 119, 130, 131, 132, 133,
         134, 135, 146, 147, 148, 149, 150, 151, 162, 163, 164, 165, 166, 167],
        [129, 130, 131, 132, 133, 134, 145, 146, 147, 148, 149, 150, 161, 162,
         163, 164, 165, 166, 177, 178, 179, 180, 181, 182, 193, 194, 195, 196,
         197, 198, 209, 210, 211, 212, 213, 214, 225, 226, 227, 228, 229, 230],
        [ 64,  65,  66,  67,  68,  69,  80,  81,  82,  83,  84,  85,  96,  97,
          98,  99, 100, 101, 112, 113, 114, 115, 116, 117, 128, 129, 130, 131,
         132, 133, 144, 145, 146, 147, 148, 149, 160, 161, 162, 163, 164, 165],
        [101, 102, 103, 104, 105, 106, 117, 118, 119, 120, 121, 122, 133, 134,
         135, 136, 137, 138, 149, 150, 151, 152, 153, 154, 165, 166, 167, 168,
         169, 170, 181, 182, 183, 184, 185, 186, 197, 198, 199, 200, 201, 202]],
       device='cuda:0')] Length: 4
Mask Target Length: 4
H: tensor([[[-8.0264e-02, -1.2221e-01, -1.6434e+00,  ..., -7.4416e-01,
          -1.3437e-01, -1.0294e+00],
         [-6.2894e-02,  8.9653e-02,  1.5794e+00,  ...,  8.5615e-01,
           7.8467e-02, -2.6172e-01],
         [-1.9652e-01, -1.5619e-01, -2.1726e+00,  ..., -2.2603e+00,
           8.6027e-02, -8.9709e-01],
         ...,
         [ 4.9319e-02, -1.0115e-01,  6.7602e-01,  ..., -2.0238e+00,
           1.5763e-01,  3.9069e-01],
         [ 3.8211e-02, -1.9994e-01,  9.3005e-01,  ..., -1.1349e+00,
           8.1685e-02,  1.5231e+00],
         [-2.3127e-01, -9.3012e-02,  1.0458e+00,  ..., -9.9948e-01,
           2.6770e-02, -9.9440e-01]],

        [[-7.3111e-02, -2.2691e-01,  3.1367e+00,  ..., -2.1377e-01,
          -1.6245e-01, -1.9505e+00],
         [ 3.9606e-02, -1.4831e-01,  9.0976e-01,  ..., -3.5592e-01,
          -2.1071e-01,  7.3279e-01],
         [-2.7068e-02, -3.1263e-02,  2.2216e+00,  ...,  2.4203e-02,
          -1.9080e-01,  1.7707e+00],
         ...,
         [ 1.0171e-01, -9.0629e-03, -6.9780e-01,  ..., -1.9848e+00,
           2.1415e-01,  1.0421e+00],
         [-9.1039e-02, -8.9204e-02,  1.3829e+00,  ..., -3.7302e-01,
          -1.3671e-01,  1.7163e-01],
         [-1.9034e-01, -1.0203e-01,  1.5089e+00,  ..., -2.6256e-02,
          -1.2439e-01,  8.2656e-01]],

        [[-1.2538e-01, -7.3717e-02,  5.4424e-01,  ...,  1.6329e+00,
           2.9533e-01, -3.5826e+00],
         [-3.3493e-01, -1.3367e-01,  1.1069e-01,  ...,  6.8371e-01,
           1.9915e-01, -4.0286e+00],
         [-3.1033e-01, -1.3218e-01, -2.7634e-01,  ...,  1.6241e+00,
           2.7214e-01, -3.7629e+00],
         ...,
         [-1.6622e-01, -3.7345e-01, -4.8468e-01,  ...,  1.8813e+00,
           3.4506e-02, -1.6707e+00],
         [-2.3714e-01, -2.8006e-01, -2.2764e-01,  ...,  1.2917e+00,
           2.9828e-01, -2.2904e+00],
         [-3.1449e-01, -4.0578e-01,  4.4992e-01,  ..., -5.6603e-01,
           2.3916e-01, -3.8403e-01]],

        ...,

        [[ 2.7413e-02, -2.4480e-01, -3.5318e-01,  ...,  5.6701e-01,
           3.5369e-02,  1.9304e+00],
         [-1.1272e-02, -1.1931e-01, -2.1117e-01,  ...,  5.1396e-01,
           2.4622e-02,  1.9105e+00],
         [-1.3084e-01, -1.3502e-01, -2.1907e+00,  ...,  4.2425e-01,
           3.4106e-02,  9.3087e-01],
         ...,
         [-3.7791e-01, -2.9657e-01, -9.1688e-01,  ..., -9.1082e-01,
          -1.7115e-01,  2.0214e+00],
         [-3.4702e-01, -2.5019e-01, -3.8185e-01,  ..., -1.7858e-01,
          -1.5936e-01,  2.6301e+00],
         [-3.5823e-01, -2.9615e-01, -2.2249e+00,  ...,  5.3021e-01,
           3.1935e-02,  6.7001e-01]],

        [[-1.1980e-01, -1.8384e-01,  1.8642e+00,  ..., -1.3379e+00,
           6.7002e-02, -4.6672e-01],
         [-6.9250e-02, -9.8687e-02,  2.5331e+00,  ..., -1.5593e+00,
           4.0752e-02, -9.2215e-01],
         [-1.4135e-01, -1.4955e-01,  3.2002e+00,  ..., -1.3380e+00,
           5.6246e-02, -8.4562e-01],
         ...,
         [ 2.0201e-02, -1.1531e-01,  9.1840e-01,  ...,  1.0945e+00,
          -3.9668e-02, -1.8718e+00],
         [ 1.1361e-02, -1.7336e-01,  5.5681e-01,  ...,  2.0509e+00,
          -1.3415e-01, -1.8819e+00],
         [-1.3258e-01, -1.7924e-01,  6.3624e-01,  ...,  1.4895e+00,
          -2.5031e-01, -1.4511e+00]],

        [[ 2.0846e-01, -1.7321e-01,  2.8299e+00,  ..., -5.2698e-01,
          -1.1925e-01, -1.8436e+00],
         [ 5.6099e-02, -1.1682e-01,  1.2092e+00,  ..., -1.9331e-01,
           5.2231e-02, -5.4395e-02],
         [ 1.7101e-02, -1.4295e-01,  1.0256e+00,  ...,  8.2568e-01,
          -1.2695e-03,  3.4655e-01],
         ...,
         [-6.2256e-02,  7.3381e-02, -7.0588e-01,  ...,  3.8131e-01,
           8.0876e-02,  1.7195e-01],
         [ 1.2338e-01, -2.3745e-01, -1.8819e+00,  ...,  1.4473e+00,
          -1.6158e-01, -1.4814e+00],
         [ 2.8549e-02, -2.3660e-01, -1.0711e+00,  ...,  1.5343e+00,
          -2.4682e-01, -2.0268e+00]]], device='cuda:0')
H-Shape: torch.Size([64, 42, 1280])
Z: tensor([[[-3.4424e-02,  3.0884e-02,  1.7334e-02,  ..., -4.9023e-01,
           7.9346e-03,  4.0430e-01],
         [ 1.6113e-02,  1.5869e-02, -5.6250e-01,  ..., -7.3047e-01,
           4.8340e-02, -2.9883e-01],
         [ 1.9165e-02,  1.4954e-02, -4.2969e-01,  ..., -7.7344e-01,
           4.7363e-02, -2.5781e-01],
         ...,
         [-2.1118e-02, -2.1820e-03,  6.9141e-01,  ...,  6.5613e-03,
           4.9072e-02, -7.4219e-01],
         [-3.8574e-02, -1.7456e-02,  1.0156e+00,  ..., -3.7891e-01,
           4.0527e-02, -7.4609e-01],
         [-8.5449e-02, -5.2734e-02,  1.3984e+00,  ..., -1.0781e+00,
          -2.3804e-03, -4.8242e-01]],

        [[-3.3447e-02, -1.0645e-01,  7.6953e-01,  ..., -8.7500e-01,
           5.4932e-02,  1.4141e+00],
         [ 1.1963e-02, -8.8867e-02,  7.6953e-01,  ..., -8.1641e-01,
           7.1289e-02,  1.4375e+00],
         [ 4.0039e-02, -7.3242e-02,  7.3828e-01,  ..., -7.4219e-01,
           7.7637e-02,  1.3750e+00],
         ...,
         [-1.1169e-02, -4.6143e-02,  7.3828e-01,  ..., -3.3594e-01,
           8.6426e-02,  1.2344e+00],
         [-1.4526e-02, -4.5654e-02,  8.3984e-01,  ..., -2.8516e-01,
           7.8125e-02,  9.1406e-01],
         [-3.5156e-02, -5.1025e-02,  9.1797e-01,  ..., -2.0605e-01,
           6.6895e-02,  6.9531e-01]],

        [[-6.7749e-03,  2.4902e-02,  2.3633e-01,  ..., -1.9043e-01,
           8.4473e-02, -1.9766e+00],
         [-2.2339e-02,  2.4414e-02,  3.5352e-01,  ..., -5.9570e-02,
           7.9590e-02, -2.1719e+00],
         [-4.9805e-02,  2.3560e-02,  4.0430e-01,  ...,  6.4941e-02,
           7.3242e-02, -2.2969e+00],
         ...,
         [-6.4453e-02,  3.0365e-03, -5.7031e-01,  ...,  2.5000e-01,
           3.6865e-02, -1.0859e+00],
         [-5.3955e-02,  2.0752e-02, -2.4609e-01,  ..., -2.6245e-02,
           5.2979e-02, -8.0078e-01],
         [-5.0049e-02,  2.1118e-02, -1.8848e-01,  ...,  1.6895e-01,
           5.6885e-02, -9.0625e-01]],

        ...,

        [[-1.4648e-01, -1.2793e-01,  1.6992e-01,  ...,  5.3516e-01,
          -2.0996e-02,  1.2969e+00],
         [-1.2354e-01, -1.0693e-01,  3.1055e-01,  ..., -2.0215e-01,
           6.1035e-03,  1.1406e+00],
         [-1.4453e-01, -1.1426e-01, -5.1514e-02,  ..., -3.7695e-01,
          -1.1047e-02,  1.3359e+00],
         ...,
         [-1.8945e-01, -4.8096e-02,  9.7168e-02,  ..., -2.4902e-01,
          -1.4160e-02,  9.9609e-01],
         [-1.9238e-01, -4.7607e-02, -1.0352e-01,  ..., -1.6602e-02,
          -1.1658e-02,  8.5547e-01],
         [-1.5723e-01, -3.2471e-02, -1.7480e-01,  ...,  1.1768e-01,
           6.2561e-03,  8.2812e-01]],

        [[-3.1494e-02,  2.4048e-02,  1.1562e+00,  ..., -7.1875e-01,
          -1.7944e-02, -2.3633e-01],
         [ 2.2888e-03, -1.7456e-02,  1.2422e+00,  ..., -3.5156e-01,
          -2.7618e-03, -2.9297e-01],
         [ 1.1719e-02, -3.2959e-02,  1.0000e+00,  ..., -3.6719e-01,
          -3.5858e-03, -1.8262e-01],
         ...,
         [-2.6489e-02, -4.8340e-02,  8.2031e-01,  ...,  1.2939e-02,
          -2.3438e-02, -8.0859e-01],
         [-2.5269e-02, -5.3955e-02,  6.9531e-01,  ...,  2.3242e-01,
          -1.6479e-02, -9.8828e-01],
         [-2.4048e-02, -6.0547e-02,  7.7344e-01,  ...,  5.0391e-01,
          -3.5095e-03, -1.1719e+00]],

        [[ 4.1992e-02, -2.8198e-02,  1.3828e+00,  ..., -7.5000e-01,
           2.1851e-02, -9.1016e-01],
         [ 5.3955e-02, -3.0762e-02,  1.1016e+00,  ..., -7.6172e-01,
           1.1108e-02, -5.6641e-01],
         [-2.1973e-02, -8.7891e-02,  3.2422e-01,  ..., -5.9766e-01,
           4.0588e-03, -1.7871e-01],
         ...,
         [-2.2217e-02, -3.6621e-02, -6.4062e-01,  ...,  9.1797e-01,
          -6.4453e-02, -1.7969e+00],
         [-2.1729e-02, -3.0029e-02, -6.0938e-01,  ...,  1.0078e+00,
          -1.0010e-01, -1.6328e+00],
         [-2.3560e-02, -2.5513e-02, -7.2266e-01,  ...,  1.1719e+00,
          -1.4258e-01, -1.8047e+00]]], device='cuda:0', dtype=torch.bfloat16,
       grad_fn=<_DDPSinkBackward>)
Z-Shape: torch.Size([64, 42, 1280])
